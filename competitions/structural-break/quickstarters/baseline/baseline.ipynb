{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWIItAe-0fN"
      },
      "source": [
        "[![Open In Colab](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/badge/open-in-colab.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/structural-break/quickstarters/baseline/baseline.ipynb)\n",
        "[![Open In Kaggle](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/badge/open-in-kaggle.svg)](https://www.kaggle.com/code/crunchdao/structural-break-baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNUXnJa_-0fO"
      },
      "source": [
        "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/structural-break/assets/banner.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lurIF1Ve-0fP"
      },
      "source": [
        "# ADIA Lab Structural Break Challenge\n",
        "\n",
        "## Challenge Overview\n",
        "\n",
        "Welcome to the ADIA Lab Structural Break Challenge! In this challenge, you will analyze univariate time series data to determine whether a structural break has occurred at a specified boundary point.\n",
        "\n",
        "### What is a Structural Break?\n",
        "\n",
        "A structural break occurs when the process governing the data generation changes at a certain point in time. These changes can be subtle or dramatic, and detecting them accurately is crucial across various domains such as climatology, industrial monitoring, finance, and healthcare.\n",
        "\n",
        "![Structural Break Example](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/competitions/structural-break/quickstarters/baseline/images/example.png)\n",
        "\n",
        "### Your Task\n",
        "\n",
        "For each time series in the test set, you need to predict a score between `0` and `1`:\n",
        "- Values closer to `0` indicate no structural break at the specified boundary point;\n",
        "- Values closer to `1` indicate a structural break did occur.\n",
        "\n",
        "### Evaluation Metric\n",
        "\n",
        "The evaluation metric is [ROC AUC (Area Under the Receiver Operating Characteristic Curve)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), which measures the performance of detection algorithms regardless of their specific calibration.\n",
        "\n",
        "- ROC AUC around `0.5`: No better than random chance;\n",
        "- ROC AUC approaching `1.0`: Perfect detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR8asLe2ixgN"
      },
      "source": [
        "# Setup\n",
        "\n",
        "The first steps to get started are:\n",
        "1. Get the setup command\n",
        "2. Execute it in the cell below\n",
        "\n",
        "### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n",
        "\n",
        "![Reveal token](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/reveal-token.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DUeixiC_IJM",
        "outputId": "8de74533-bb81-429a-bb6c-9465431ba0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crunch-cli, version 7.5.0\n",
            "main.py: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/submissions/29012/main.py (5864 bytes)\n",
            "notebook.ipynb: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/submissions/29012/notebook.ipynb (74090 bytes)\n",
            "requirements.txt: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/submissions/29012/requirements.original.txt (203 bytes)\n",
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "                                \n",
            "---\n",
            "Success! Your environment has been correctly setup.\n",
            "Next recommended actions:\n",
            "1. Load the Crunch Toolings: `crunch = crunch.load_notebook()`\n",
            "2. Execute the cells with your code\n",
            "3. Run a test: `crunch.test()`\n",
            "4. Download and submit your code to the platform!\n"
          ]
        }
      ],
      "source": [
        "%pip install crunch-cli --upgrade --quiet --progress-bar off\n",
        "!crunch setup-notebook structural-break Z1nLW76rKrAZxriHTfIpS1tm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import typing\n",
        "\n",
        "# Import your dependencies\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import sklearn.metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import crunch\n",
        "\n",
        "# Load the Crunch Toolings\n",
        "crunch = crunch.load_notebook()\n",
        "\n",
        "# Load the data simply\n",
        "X_train, y_train, X_test = crunch.load_data()"
      ],
      "metadata": {
        "id": "Sjr8Z1x4j_PZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: pd.Series,\n",
        "    model_directory_path: str,\n",
        "):\n",
        "    def extract_features(df: pd.DataFrame) -> dict:\n",
        "        \"\"\"Extract comprehensive features from time series segments\"\"\"\n",
        "        before = df[df[\"period\"] == 0][\"value\"]\n",
        "        after = df[df[\"period\"] == 1][\"value\"]\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        # Basic statistics\n",
        "        features['mean_diff'] = np.abs(after.mean() - before.mean())\n",
        "        features['std_diff'] = np.abs(after.std() - before.std())\n",
        "        features['var_ratio'] = after.var() / (before.var() + 1e-8)\n",
        "        features['median_diff'] = np.abs(after.median() - before.median())\n",
        "\n",
        "        # Distribution tests\n",
        "        try:\n",
        "            _, features['ttest_pvalue'] = scipy.stats.ttest_ind(before, after)\n",
        "        except:\n",
        "            features['ttest_pvalue'] = 0.5\n",
        "\n",
        "        try:\n",
        "            _, features['ks_pvalue'] = scipy.stats.ks_2samp(before, after)\n",
        "        except:\n",
        "            features['ks_pvalue'] = 0.5\n",
        "\n",
        "        try:\n",
        "            _, features['mannwhitney_pvalue'] = scipy.stats.mannwhitneyu(before, after)\n",
        "        except:\n",
        "            features['mannwhitney_pvalue'] = 0.5\n",
        "\n",
        "        # Trend analysis\n",
        "        try:\n",
        "            before_trend = np.polyfit(range(len(before)), before, 1)[0] if len(before) > 1 else 0\n",
        "            after_trend = np.polyfit(range(len(after)), after, 1)[0] if len(after) > 1 else 0\n",
        "            features['trend_change'] = np.abs(after_trend - before_trend)\n",
        "        except:\n",
        "            features['trend_change'] = 0\n",
        "\n",
        "        # Volatility measures\n",
        "        try:\n",
        "            before_vol = before.rolling(min(10, len(before)//2), min_periods=1).std().mean()\n",
        "            after_vol = after.rolling(min(10, len(after)//2), min_periods=1).std().mean()\n",
        "            features['volatility_change'] = np.abs(after_vol - before_vol)\n",
        "        except:\n",
        "            features['volatility_change'] = 0\n",
        "\n",
        "        # Quantile differences\n",
        "        for q in [0.25, 0.5, 0.75, 0.9]:\n",
        "            try:\n",
        "                features[f'quantile_{q}_diff'] = np.abs(after.quantile(q) - before.quantile(q))\n",
        "            except:\n",
        "                features[f'quantile_{q}_diff'] = 0\n",
        "\n",
        "        # Range and IQR changes\n",
        "        features['range_before'] = before.max() - before.min()\n",
        "        features['range_after'] = after.max() - after.min()\n",
        "        features['range_change'] = np.abs(features['range_after'] - features['range_before'])\n",
        "\n",
        "        # Skewness and kurtosis changes\n",
        "        try:\n",
        "            features['skew_change'] = np.abs(scipy.stats.skew(after) - scipy.stats.skew(before))\n",
        "            features['kurtosis_change'] = np.abs(scipy.stats.kurtosis(after) - scipy.stats.kurtosis(before))\n",
        "        except:\n",
        "            features['skew_change'] = 0\n",
        "            features['kurtosis_change'] = 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    # Extract features for all training time series\n",
        "    feature_list = []\n",
        "    labels = []\n",
        "\n",
        "    for ts_id in X_train.index.get_level_values('id').unique():\n",
        "        ts_data = X_train.loc[ts_id]\n",
        "        features = extract_features(ts_data)\n",
        "        feature_list.append(features)\n",
        "        labels.append(y_train.loc[ts_id])\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    feature_df = pd.DataFrame(feature_list)\n",
        "\n",
        "    # Handle missing values\n",
        "    feature_df = feature_df.fillna(0)\n",
        "    feature_df = feature_df.replace([np.inf, -np.inf], 0)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(feature_df)\n",
        "\n",
        "    # Train Random Forest classifier\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    model.fit(scaled_features, labels)\n",
        "\n",
        "    # Save model and scaler\n",
        "    joblib.dump({\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'feature_columns': feature_df.columns.tolist(),\n",
        "        'extract_features': extract_features\n",
        "    }, os.path.join(model_directory_path, 'model.joblib'))"
      ],
      "metadata": {
        "id": "_gb2QFAWkf6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IBhw7hv-0fQ"
      },
      "source": [
        "# Your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDZeP-4--0fU"
      },
      "outputs": [],
      "source": [
        "crunch.test(\n",
        "    # Uncomment to disable the train\n",
        "    # force_first_train=False,\n",
        "\n",
        "    # Uncomment to disable the determinism check\n",
        "    # no_determinism_check=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV_5CKs--0fU"
      },
      "source": [
        "## Results\n",
        "\n",
        "Once the local tester is done, you can preview the result stored in `data/prediction.parquet`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly5q68sA-0fU"
      },
      "outputs": [],
      "source": [
        "prediction = pd.read_parquet(\"data/prediction.parquet\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oP-NLGh-0fU"
      },
      "source": [
        "### Local scoring\n",
        "\n",
        "You can call the function that the system uses to estimate your score locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyCrjpzv-0fU"
      },
      "outputs": [],
      "source": [
        "# Load the targets\n",
        "target = pd.read_parquet(\"data/y_test.reduced.parquet\")[\"structural_breakpoint\"]\n",
        "\n",
        "# Call the scoring function\n",
        "sklearn.metrics.roc_auc_score(\n",
        "    target,\n",
        "    prediction,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}